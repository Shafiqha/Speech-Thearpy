#!/usr/bin/env python3
"""
Interactive Speech Therapy System for Aphasia Patients
Progressive sentence practice with adaptive difficulty
"""

from dataclasses import dataclass
from typing import Dict, List, Tuple, Any

import difflib
try:
    from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# Import our modules
try:
    # Try relative imports first (when used as a package)
    from .train_simple import SimpleAphasiaModel
    from .simple_tts import ReliableTTS
    from .feedback_reader import FeedbackReader
except ImportError:
    # Fall back to direct imports (when run directly)
    from train_simple import SimpleAphasiaModel
    from simple_tts import ReliableTTS
    from feedback_reader import FeedbackReader

import os
import json
import time
import random
import torch
import numpy as np
import librosa
from typing import Dict, List, Tuple
from dataclasses import dataclass, asdict
import pandas as pd
from pathlib import Path

def levenshtein_distance(s1: str, s2: str) -> int:
    """Calculate Levenshtein distance between two strings."""
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)

    if len(s2) == 0:
        return len(s1)

    previous_row = list(range(len(s2) + 1))
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]

def calculate_similarity(target: str, transcription: str) -> float:
    """Calculate similarity percentage using Levenshtein distance."""
    if not target or not transcription:
        return 0.0
    
    # Normalize strings
    target = target.strip().lower()
    transcription = transcription.strip().lower()
    
    if target == transcription:
        return 100.0
    
    # Calculate Levenshtein distance
    distance = levenshtein_distance(target, transcription)
    max_len = max(len(target), len(transcription))
    
    if max_len == 0:
        return 100.0
    
    # Convert to similarity percentage
    similarity = ((max_len - distance) / max_len) * 100
    return max(0.0, similarity)

@dataclass
class TherapySentence:
    """Represents a therapy sentence with metadata."""
    text: str
    language: str
    difficulty: str  # 'easy', 'medium', 'hard'
    category: str    # 'greeting', 'family', 'food', 'daily', etc.
    target_words: List[str]  # Key words to focus on

@dataclass
class TherapySession:
    """Tracks therapy session progress."""
    patient_id: str
    language: str
    start_time: str
    current_sentence_index: int = 0
    current_difficulty: str = 'easy'
    total_attempts: int = 0
    correct_attempts: int = 0
    average_severity: float = 0.0
    session_sentences: List[Dict] = None

    def __post_init__(self):
        if self.session_sentences is None:
            self.session_sentences = []

class InteractiveSpeechTherapy:
    """Interactive speech therapy system with progressive difficulty."""

    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.session = None
        self.sentences_db = self._load_sentences_database()
        self.tts = ReliableTTS()
        self.asr_model = None
        self.asr_processor = None
        self.severity_model = None

        print("üè• INTERACTIVE SPEECH THERAPY SYSTEM")
        print("="*60)

    def _load_sentences_database(self) -> Dict[str, List[TherapySentence]]:
        """Load therapy sentences organized by language and difficulty."""

        sentences_db = {
            'en': {
                'easy': [
                    TherapySentence("Hello", 'en', 'easy', 'greeting', ['Hello']),
                    TherapySentence("Thank you", 'en', 'easy', 'polite', ['Thank', 'you']),
                    TherapySentence("Yes", 'en', 'easy', 'response', ['Yes']),
                    TherapySentence("No", 'en', 'easy', 'response', ['No']),
                    TherapySentence("Water", 'en', 'easy', 'basic', ['Water']),
                    TherapySentence("Food", 'en', 'easy', 'basic', ['Food']),
                    TherapySentence("Home", 'en', 'easy', 'basic', ['Home']),
                    TherapySentence("Good", 'en', 'easy', 'feeling', ['Good']),
                    TherapySentence("Bad", 'en', 'easy', 'feeling', ['Bad']),
                    TherapySentence("Help", 'en', 'easy', 'request', ['Help']),
                ],
                'medium': [
                    TherapySentence("I am hungry", 'en', 'medium', 'feeling', ['I', 'am', 'hungry']),
                    TherapySentence("I need water", 'en', 'medium', 'request', ['I', 'need', 'water']),
                    TherapySentence("How are you", 'en', 'medium', 'greeting', ['How', 'are', 'you']),
                    TherapySentence("I want to go home", 'en', 'medium', 'desire', ['I', 'want', 'go', 'home']),
                    TherapySentence("The cat is black", 'en', 'medium', 'description', ['The', 'cat', 'is', 'black']),
                    TherapySentence("I love you", 'en', 'medium', 'emotion', ['I', 'love', 'you']),
                    TherapySentence("Please help me", 'en', 'medium', 'request', ['Please', 'help', 'me']),
                    TherapySentence("What is your name", 'en', 'medium', 'question', ['What', 'is', 'your', 'name']),
                    TherapySentence("I am reading a book", 'en', 'medium', 'activity', ['I', 'am', 'reading', 'book']),
                    TherapySentence("The weather is nice", 'en', 'medium', 'description', ['The', 'weather', 'is', 'nice']),
                ],
                'hard': [
                    TherapySentence("I would like to speak with the doctor", 'en', 'hard', 'medical', ['I', 'would', 'like', 'speak', 'doctor']),
                    TherapySentence("My family is coming to visit tomorrow", 'en', 'hard', 'family', ['My', 'family', 'coming', 'visit', 'tomorrow']),
                    TherapySentence("I need to buy groceries for dinner", 'en', 'hard', 'shopping', ['I', 'need', 'buy', 'groceries', 'dinner']),
                    TherapySentence("The medication makes me feel better", 'en', 'hard', 'medical', ['The', 'medication', 'makes', 'feel', 'better']),
                    TherapySentence("I enjoy listening to music in the evening", 'en', 'hard', 'hobby', ['I', 'enjoy', 'listening', 'music', 'evening']),
                ]
            },
            'hi': {
                'easy': [
                    TherapySentence("‡§®‡§Æ‡§∏‡•ç‡§§‡•á", 'hi', 'easy', 'greeting', ['‡§®‡§Æ‡§∏‡•ç‡§§‡•á']),
                    TherapySentence("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶", 'hi', 'easy', 'polite', ['‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶']),
                    TherapySentence("‡§π‡§æ‡§Å", 'hi', 'easy', 'response', ['‡§π‡§æ‡§Å']),
                    TherapySentence("‡§®‡§π‡•Ä‡§Ç", 'hi', 'easy', 'response', ['‡§®‡§π‡•Ä‡§Ç']),
                    TherapySentence("‡§™‡§æ‡§®‡•Ä", 'hi', 'easy', 'basic', ['‡§™‡§æ‡§®‡•Ä']),
                    TherapySentence("‡§ñ‡§æ‡§®‡§æ", 'hi', 'easy', 'basic', ['‡§ñ‡§æ‡§®‡§æ']),
                    TherapySentence("‡§ò‡§∞", 'hi', 'easy', 'basic', ['‡§ò‡§∞']),
                    TherapySentence("‡§Ö‡§ö‡•ç‡§õ‡§æ", 'hi', 'easy', 'feeling', ['‡§Ö‡§ö‡•ç‡§õ‡§æ']),
                    TherapySentence("‡§¨‡•Å‡§∞‡§æ", 'hi', 'easy', 'feeling', ['‡§¨‡•Å‡§∞‡§æ']),
                    TherapySentence("‡§Æ‡§¶‡§¶", 'hi', 'easy', 'request', ['‡§Æ‡§¶‡§¶']),
                ],
                'medium': [
                    TherapySentence("‡§Æ‡•Å‡§ù‡•á ‡§≠‡•Ç‡§ñ ‡§≤‡§ó‡•Ä ‡§π‡•à", 'hi', 'medium', 'feeling', ['‡§Æ‡•Å‡§ù‡•á', '‡§≠‡•Ç‡§ñ', '‡§≤‡§ó‡•Ä']),
                    TherapySentence("‡§Æ‡•Å‡§ù‡•á ‡§™‡§æ‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è", 'hi', 'medium', 'request', ['‡§Æ‡•Å‡§ù‡•á', '‡§™‡§æ‡§®‡•Ä', '‡§ö‡§æ‡§π‡§ø‡§è']),
                    TherapySentence("‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç", 'hi', 'medium', 'greeting', ['‡§Ü‡§™', '‡§ï‡•à‡§∏‡•á', '‡§π‡•à‡§Ç']),
                    TherapySentence("‡§Æ‡•à‡§Ç ‡§ò‡§∞ ‡§ú‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Ç", 'hi', 'medium', 'desire', ['‡§Æ‡•à‡§Ç', '‡§ò‡§∞', '‡§ú‡§æ‡§®‡§æ', '‡§ö‡§æ‡§π‡§§‡§æ']),
                    TherapySentence("‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§ï‡§æ‡§≤‡•Ä ‡§π‡•à", 'hi', 'medium', 'description', ['‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ä', '‡§ï‡§æ‡§≤‡•Ä']),
                    TherapySentence("‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§∏‡•á ‡§™‡•ç‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Ç", 'hi', 'medium', 'emotion', ['‡§Æ‡•à‡§Ç', '‡§Ü‡§™‡§∏‡•á', '‡§™‡•ç‡§Ø‡§æ‡§∞']),
                    TherapySentence("‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡•á‡§Ç", 'hi', 'medium', 'request', ['‡§ï‡•É‡§™‡§Ø‡§æ', '‡§Æ‡•á‡§∞‡•Ä', '‡§Æ‡§¶‡§¶']),
                    TherapySentence("‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à", 'hi', 'medium', 'question', ['‡§Ü‡§™‡§ï‡§æ', '‡§®‡§æ‡§Æ', '‡§ï‡•ç‡§Ø‡§æ']),
                    TherapySentence("‡§Æ‡•à‡§Ç ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§™‡§¢‡§º ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç", 'hi', 'medium', 'activity', ['‡§Æ‡•à‡§Ç', '‡§ï‡§ø‡§§‡§æ‡§¨', '‡§™‡§¢‡§º']),
                    TherapySentence("‡§Æ‡•å‡§∏‡§Æ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à", 'hi', 'medium', 'description', ['‡§Æ‡•å‡§∏‡§Æ', '‡§Ö‡§ö‡•ç‡§õ‡§æ']),
                ],
                'hard': [
                    TherapySentence("‡§Æ‡•à‡§Ç ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Ç", 'hi', 'hard', 'medical', ['‡§Æ‡•à‡§Ç', '‡§°‡•â‡§ï‡•ç‡§ü‡§∞', '‡§¨‡§æ‡§§', '‡§ö‡§æ‡§π‡§§‡§æ']),
                    TherapySentence("‡§Æ‡•á‡§∞‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡§≤ ‡§Æ‡§ø‡§≤‡§®‡•á ‡§Ü ‡§∞‡§π‡§æ ‡§π‡•à", 'hi', 'hard', 'family', ['‡§Æ‡•á‡§∞‡§æ', '‡§™‡§∞‡§ø‡§µ‡§æ‡§∞', '‡§ï‡§≤', '‡§Æ‡§ø‡§≤‡§®‡•á']),
                    TherapySentence("‡§Æ‡•Å‡§ù‡•á ‡§∞‡§æ‡§§ ‡§ï‡•á ‡§ñ‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§æ‡§Æ‡§æ‡§® ‡§ñ‡§∞‡•Ä‡§¶‡§®‡§æ ‡§π‡•à", 'hi', 'hard', 'shopping', ['‡§Æ‡•Å‡§ù‡•á', '‡§ñ‡§æ‡§®‡•á', '‡§∏‡§æ‡§Æ‡§æ‡§®', '‡§ñ‡§∞‡•Ä‡§¶‡§®‡§æ']),
                    TherapySentence("‡§¶‡§µ‡§æ ‡§∏‡•á ‡§Æ‡•Å‡§ù‡•á ‡§¨‡•á‡§π‡§§‡§∞ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§π‡•ã‡§§‡§æ ‡§π‡•à", 'hi', 'hard', 'medical', ['‡§¶‡§µ‡§æ', '‡§Æ‡•Å‡§ù‡•á', '‡§¨‡•á‡§π‡§§‡§∞', '‡§Æ‡§π‡§∏‡•Ç‡§∏']),
                    TherapySentence("‡§Æ‡•à‡§Ç ‡§∂‡§æ‡§Æ ‡§ï‡•ã ‡§∏‡§Ç‡§ó‡•Ä‡§§ ‡§∏‡•Å‡§®‡§®‡§æ ‡§™‡§∏‡§Ç‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Ç", 'hi', 'hard', 'hobby', ['‡§Æ‡•à‡§Ç', '‡§∂‡§æ‡§Æ', '‡§∏‡§Ç‡§ó‡•Ä‡§§', '‡§∏‡•Å‡§®‡§®‡§æ', '‡§™‡§∏‡§Ç‡§¶']),
                ]
            },
            'kn': {
                'easy': [
                    TherapySentence("‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞", 'kn', 'easy', 'greeting', ['‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞']),
                    TherapySentence("‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å", 'kn', 'easy', 'polite', ['‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å']),
                    TherapySentence("‡≤π‡≥å‡≤¶‡≥Å", 'kn', 'easy', 'response', ['‡≤π‡≥å‡≤¶‡≥Å']),
                    TherapySentence("‡≤á‡≤≤‡≥ç‡≤≤", 'kn', 'easy', 'response', ['‡≤á‡≤≤‡≥ç‡≤≤']),
                    TherapySentence("‡≤®‡≥Ä‡≤∞‡≥Å", 'kn', 'easy', 'basic', ['‡≤®‡≥Ä‡≤∞‡≥Å']),
                    TherapySentence("‡≤ä‡≤ü", 'kn', 'easy', 'basic', ['‡≤ä‡≤ü']),
                    TherapySentence("‡≤Æ‡≤®‡≥Ü", 'kn', 'easy', 'basic', ['‡≤Æ‡≤®‡≥Ü']),
                    TherapySentence("‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å", 'kn', 'easy', 'feeling', ['‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å']),
                    TherapySentence("‡≤ï‡≥Ü‡≤ü‡≥ç‡≤ü‡≤¶‡≥Å", 'kn', 'easy', 'feeling', ['‡≤ï‡≥Ü‡≤ü‡≥ç‡≤ü‡≤¶‡≥Å']),
                    TherapySentence("‡≤∏‡≤π‡≤æ‡≤Ø", 'kn', 'easy', 'request', ['‡≤∏‡≤π‡≤æ‡≤Ø']),
                ],
                'medium': [
                    TherapySentence("‡≤®‡≤®‡≤ó‡≥Ü ‡≤π‡≤∏‡≤ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü", 'kn', 'medium', 'feeling', ['‡≤®‡≤®‡≤ó‡≥Ü', '‡≤π‡≤∏‡≤ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü']),
                    TherapySentence("‡≤®‡≤®‡≤ó‡≥Ü ‡≤®‡≥Ä‡≤∞‡≥Å ‡≤¨‡≥á‡≤ï‡≥Å", 'kn', 'medium', 'request', ['‡≤®‡≤®‡≤ó‡≥Ü', '‡≤®‡≥Ä‡≤∞‡≥Å', '‡≤¨‡≥á‡≤ï‡≥Å']),
                    TherapySentence("‡≤®‡≥Ä‡≤µ‡≥Å ‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø", 'kn', 'medium', 'greeting', ['‡≤®‡≥Ä‡≤µ‡≥Å', '‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø']),
                    TherapySentence("‡≤®‡≤æ‡≤®‡≥Å ‡≤Æ‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤π‡≥ã‡≤ó‡≤¨‡≥á‡≤ï‡≥Å", 'kn', 'medium', 'desire', ['‡≤®‡≤æ‡≤®‡≥Å', '‡≤Æ‡≤®‡≥Ü‡≤ó‡≥Ü', '‡≤π‡≥ã‡≤ó‡≤¨‡≥á‡≤ï‡≥Å']),
                    TherapySentence("‡≤¨‡≥Ü‡≤ï‡≥ç‡≤ï‡≥Å ‡≤ï‡≤™‡≥ç‡≤™‡≥Å", 'kn', 'medium', 'description', ['‡≤¨‡≥Ü‡≤ï‡≥ç‡≤ï‡≥Å', '‡≤ï‡≤™‡≥ç‡≤™‡≥Å']),
                    TherapySentence("‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü", 'kn', 'medium', 'emotion', ['‡≤®‡≤æ‡≤®‡≥Å', '‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ‡≤®‡≥ç‡≤®‡≥Å', '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü']),
                    TherapySentence("‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤®‡≤®‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≤ø", 'kn', 'medium', 'request', ['‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å', '‡≤®‡≤®‡≤ó‡≥Ü', '‡≤∏‡≤π‡≤æ‡≤Ø']),
                    TherapySentence("‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å ‡≤è‡≤®‡≥Å", 'kn', 'medium', 'question', ['‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ', '‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å', '‡≤è‡≤®‡≥Å']),
                    TherapySentence("‡≤®‡≤æ‡≤®‡≥Å ‡≤™‡≥Å‡≤∏‡≥ç‡≤§‡≤ï ‡≤ì‡≤¶‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü", 'kn', 'medium', 'activity', ['‡≤®‡≤æ‡≤®‡≥Å', '‡≤™‡≥Å‡≤∏‡≥ç‡≤§‡≤ï', '‡≤ì‡≤¶‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü']),
                    TherapySentence("‡≤π‡≤µ‡≤æ‡≤Æ‡≤æ‡≤® ‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü", 'kn', 'medium', 'description', ['‡≤π‡≤µ‡≤æ‡≤Æ‡≤æ‡≤®', '‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü']),
                ],
                'hard': [
                    TherapySentence("‡≤®‡≤æ‡≤®‡≥Å ‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Å", 'kn', 'hard', 'medical', ['‡≤®‡≤æ‡≤®‡≥Å', '‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü', '‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Å']),
                    TherapySentence("‡≤®‡≤®‡≥ç‡≤® ‡≤ï‡≥Å‡≤ü‡≥Å‡≤Ç‡≤¨ ‡≤®‡≤æ‡≤≥‡≥Ü ‡≤≠‡≥á‡≤ü‡≤ø ‡≤®‡≥Ä‡≤°‡≤≤‡≤ø‡≤¶‡≥Ü", 'kn', 'hard', 'family', ['‡≤®‡≤®‡≥ç‡≤®', '‡≤ï‡≥Å‡≤ü‡≥Å‡≤Ç‡≤¨', '‡≤®‡≤æ‡≤≥‡≥Ü', '‡≤≠‡≥á‡≤ü‡≤ø']),
                    TherapySentence("‡≤®‡≤®‡≤ó‡≥Ü ‡≤∞‡≤æ‡≤§‡≥ç‡≤∞‡≤ø ‡≤ä‡≤ü‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥Å ‡≤§‡≥Ü‡≤ó‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤¨‡≥á‡≤ï‡≥Å", 'kn', 'hard', 'shopping', ['‡≤®‡≤®‡≤ó‡≥Ü', '‡≤ä‡≤ü‡≤ï‡≥ç‡≤ï‡≥Ü', '‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥Å', '‡≤§‡≥Ü‡≤ó‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤¨‡≥á‡≤ï‡≥Å']),
                    TherapySentence("‡≤î‡≤∑‡≤ß‡≤ø‡≤Ø‡≤ø‡≤Ç‡≤¶ ‡≤®‡≤®‡≤ó‡≥Ü ‡≤â‡≤§‡≥ç‡≤§‡≤Æ‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü", 'kn', 'hard', 'medical', ['‡≤î‡≤∑‡≤ß‡≤ø‡≤Ø‡≤ø‡≤Ç‡≤¶', '‡≤®‡≤®‡≤ó‡≥Ü', '‡≤â‡≤§‡≥ç‡≤§‡≤Æ‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü']),
                    TherapySentence("‡≤®‡≤æ‡≤®‡≥Å ‡≤∏‡≤Ç‡≤ú‡≥Ü ‡≤∏‡≤Ç‡≤ó‡≥Ä‡≤§ ‡≤ï‡≥á‡≤≥‡≤≤‡≥Å ‡≤á‡≤∑‡≥ç‡≤ü‡≤™‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü", 'kn', 'hard', 'hobby', ['‡≤®‡≤æ‡≤®‡≥Å', '‡≤∏‡≤Ç‡≤ú‡≥Ü', '‡≤∏‡≤Ç‡≤ó‡≥Ä‡≤§', '‡≤ï‡≥á‡≤≥‡≤≤‡≥Å', '‡≤á‡≤∑‡≥ç‡≤ü‡≤™‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü']),
                ]
            }
        }

        return sentences_db

    def get_sentence_by_severity(self, language: str = "en", wab_score: float = 50) -> TherapySentence:
        """Get appropriate sentence based on WAB-AQ severity score."""
        
        # Determine difficulty based on WAB-AQ score
        if wab_score <= 25:  # Very Severe (0-25)
            difficulty = "easy"
            print(f"üî¥ Very Severe (WAB-AQ: {wab_score}) ‚Üí Easy sentences")
        elif wab_score <= 50:  # Severe (26-50)
            difficulty = "easy" 
            print(f"üü† Severe (WAB-AQ: {wab_score}) ‚Üí Easy sentences")
        elif wab_score <= 75:  # Moderate (51-75)
            difficulty = "medium"
            print(f"üü° Moderate (WAB-AQ: {wab_score}) ‚Üí Medium sentences")
        else:  # Mild (76-100)
            difficulty = "hard"
            print(f"üü¢ Mild (WAB-AQ: {wab_score}) ‚Üí Hard sentences")
        
        # Get sentences for the language and difficulty
        if language not in self.sentences_db:
            language = "en"  # Fallback to English
        
        if difficulty not in self.sentences_db[language]:
            difficulty = "easy"  # Fallback to easy
        
        sentences = self.sentences_db[language][difficulty]
        
        if not sentences:
            # Fallback to any available sentences
            for diff in ['easy', 'medium', 'hard']:
                if diff in self.sentences_db[language] and self.sentences_db[language][diff]:
                    sentences = self.sentences_db[language][diff]
                    difficulty = diff
                    break
        
        if sentences:
            # Cycle through sentences
            if not hasattr(self, '_sentence_index'):
                self._sentence_index = {}
            
            key = f"{language}_{difficulty}"
            if key not in self._sentence_index:
                self._sentence_index[key] = 0
            
            sentence = sentences[self._sentence_index[key] % len(sentences)]
            self._sentence_index[key] += 1
            
            print(f"üìù Selected: '{sentence.text}' ({sentence.difficulty} difficulty)")
            return sentence
        
        # Ultimate fallback
        return TherapySentence("Hello", "en", "easy", "greeting", ["Hello"])

    # -----------------------------
    # Interactive Language Selection
    # -----------------------------
    def select_language_interactive(self) -> str:
        print("\n" + "="*60)
        print("üè• SPEECH THERAPY SYSTEM")
        print("="*60)
        print("Please select your language:\n")
        print("1Ô∏è‚É£  English (en) - Example: 'Hello, how are you?'")
        print("2Ô∏è‚É£  Hindi (hi) - ‡§π‡§ø‡§Ç‡§¶‡•Ä - Example: '‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç ‡§Ü‡§™?'")
        print("3Ô∏è‚É£  Kannada (kn) - ‡≤ï‡≤®‡≥ç‡≤®‡≤° - Example: '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞ ‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤æ?'\n")
        print("-" * 60)

        while True:
            choice = input("üéØ Enter your choice (1, 2, or 3): ").strip()
            if choice == '1':
                print("‚úÖ Selected: English")
                return 'en'
            elif choice == '2':
                print("‚úÖ Selected: Hindi - ‡§π‡§ø‡§Ç‡§¶‡•Ä")
                return 'hi'
            elif choice == '3':
                print("‚úÖ Selected: Kannada - ‡≤ï‡≤®‡≥ç‡≤®‡≤°")
                return 'kn'
            else:
                print("‚ùå Invalid choice. Please enter 1, 2, or 3.")
                continue

    # -----------------------------
    # Load Models
    # -----------------------------
    def load_models(self, language: str = "en"):
        print("\nüîÑ Loading models...")

        # Select models based on language
        if language == "hi":
            asr_candidates = [
                "facebook/wav2vec2-large-xlsr-53-hindi",  # Hindi-specific
                "facebook/wav2vec2-large-xlsr-53",  # Multilingual fallback
            ]
        elif language == "kn":
            # Kannada-specific models in order of quality
            asr_candidates = [
                "Harveenchadha/vakyansh-wav2vec2-kannada-knm-100",  # Vakyansh Kannada (best)
                "ai4bharat/indicwav2vec_v1_kn",                      # AI4Bharat Kannada
                "facebook/mms-1b-all",                               # Meta MMS multilingual
                "facebook/wav2vec2-large-xlsr-53",                   # XLSR multilingual fallback
            ]
        else:
            asr_candidates = [
                "facebook/wav2vec2-base-960h",  # English
                "facebook/wav2vec2-large-xlsr-53",  # Multilingual fallback
            ]

        if TRANSFORMERS_AVAILABLE:
            for candidate in asr_candidates:
                try:
                    print(f"üîç Trying to load: {candidate}")
                    
                    if os.path.exists(candidate):
                        processor_source = candidate
                        model_source = candidate
                    else:
                        processor_source = candidate
                        model_source = candidate

                    self.asr_processor = Wav2Vec2Processor.from_pretrained(processor_source)
                    if hasattr(self.asr_processor, "tokenizer") and hasattr(self.asr_processor.tokenizer, "init_kwargs"):
                        self.asr_processor.tokenizer.init_kwargs.setdefault("tokenizer_class", "Wav2Vec2CTCTokenizer")
                    self.asr_model = Wav2Vec2ForCTC.from_pretrained(model_source).to(self.device)

                    location = "local" if os.path.exists(candidate) else "pretrained"
                    print(f"‚úÖ ASR model loaded from {candidate} ({location}) for language: {language}")
                    break
                except Exception as e:
                    print(f"‚ö†Ô∏è Unable to load ASR model from '{candidate}': {e}")
                    self.asr_model = None
                    self.asr_processor = None
                    continue

        if not self.asr_model or not self.asr_processor:
            print("‚ùå No ASR model available. Transcription will be skipped.")

        # Severity model
        try:
            self.severity_model = SimpleAphasiaModel()
            if os.path.exists("models/simple_best_model.pt"):
                checkpoint = torch.load("models/simple_best_model.pt", map_location='cpu')
                self.severity_model.load_state_dict(checkpoint['model_state_dict'])
                print("‚úÖ Severity model loaded")
            else:
                print("‚ö†Ô∏è Using untrained severity model")
            # Keep model on CPU to avoid device mismatches
            self.severity_model.to('cpu')
            self.severity_model.eval()
        except Exception as e:
            print(f"‚ùå Severity model failed: {e}")

    # -----------------------------
    # Record Audio
    # -----------------------------
    def record_speech(self, duration: int = 5) -> str:
        try:
            import pyaudio
            import wave
            import tempfile

            print(f"\nüéôÔ∏è  Recording for {duration} seconds...")
            print("üó£Ô∏è  Speak clearly NOW!")

            CHUNK = 1024
            FORMAT = pyaudio.paInt16
            CHANNELS = 1
            RATE = 16000

            p = pyaudio.PyAudio()
            stream = p.open(format=FORMAT,
                            channels=CHANNELS,
                            rate=RATE,
                            input=True,
                            frames_per_buffer=CHUNK)

            frames = []

            for i in range(0, duration * RATE // CHUNK):
                data = stream.read(CHUNK)
                frames.append(data)
                if i % (RATE // CHUNK) == 0:
                    remaining = duration - (i * CHUNK // RATE)
                    if remaining > 0:
                        print(f"‚è±Ô∏è  Recording... {remaining}s remaining")

            print("‚úÖ Recording complete!")
            stream.stop_stream()
            stream.close()
            p.terminate()

            temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            wf = wave.open(temp_file.name, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(p.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()

            return temp_file.name
        except Exception as e:
            print(f"‚ùå Recording failed: {e}")
            return None

    # -----------------------------
    # Transcribe Audio
    # -----------------------------
    def transcribe_audio(self, audio_path: str, language: str = "en", target_sentence: str = "") -> str:
        if not self.asr_model or not self.asr_processor:
            print("‚ùå ASR model or processor not loaded")
            return ""

        try:
            # Load and preprocess audio
            audio, sr = librosa.load(audio_path, sr=16000)
            print(f"üéµ Loaded audio: {len(audio)} samples, {len(audio)/sr:.2f}s, max: {np.max(np.abs(audio)):.3f}")
            
            # Check if audio is too quiet or empty
            if len(audio) == 0:
                print("‚ùå Empty audio file")
                return ""
            
            if np.max(np.abs(audio)) < 0.001:
                print("‚ùå Audio too quiet")
                return ""
            
            # Audio enhancement for better transcription
            try:
                audio = self._enhance_audio_quality(audio)
                print(f"‚úÖ Audio enhanced, new max: {np.max(np.abs(audio)):.3f}")
            except Exception as e:
                print(f"‚ö†Ô∏è Audio enhancement failed: {e}, using original")
            
            # Ensure minimum length for better recognition
            min_length = int(0.5 * 16000)  # 0.5 seconds minimum
            if len(audio) < min_length:
                audio = np.pad(audio, (0, min_length - len(audio)))
                print(f"üìè Padded audio to {len(audio)} samples")
            
            # Normalize audio
            max_val = np.max(np.abs(audio))
            if max_val > 0:
                audio = audio / max_val
                print(f"üîß Normalized audio, new max: {np.max(np.abs(audio)):.3f}")

            # Process with ASR model
            print("ü§ñ Processing with ASR model...")
            inputs = self.asr_processor(audio, sampling_rate=16000, return_tensors="pt", padding=True)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            print(f"üìä Input tensor shape: {inputs['input_values'].shape}")

            with torch.no_grad():
                logits = self.asr_model(**inputs).logits
                print(f"üìà Logits shape: {logits.shape}")

            # Decode with multiple methods for better results
            predicted_ids = torch.argmax(logits, dim=-1)
            transcription = self.asr_processor.batch_decode(predicted_ids)[0]
            print(f"üî§ Raw transcription: '{transcription}'")
            
            # If empty, try alternative decoding
            if not transcription or transcription.strip() == "":
                print("‚ö†Ô∏è Empty transcription, trying alternative decoding...")
                # Try with skip_special_tokens=False
                transcription = self.asr_processor.batch_decode(predicted_ids, skip_special_tokens=False)[0]
                print(f"üî§ Alternative transcription: '{transcription}'")
            
            # Clean up common ASR artifacts
            transcription = self._clean_asr_artifacts(transcription)
            print(f"üßπ After artifact cleanup: '{transcription}'")

            # Post-process for language-specific corrections - NO FALLBACKS
            if language == "hi":
                transcription = self._clean_hindi_transcription(transcription)
                print(f"‚úÖ Hindi ASR raw output: '{transcription}' - using as-is")
            elif language == "kn":
                transcription = self._clean_kannada_transcription(transcription)
                print(f"‚úÖ Kannada ASR raw output: '{transcription}' - using as-is")
            else:
                # For English, apply basic cleaning only
                transcription = self._clean_english_transcription(transcription)
                print(f"‚úÖ English ASR raw output: '{transcription}' - using as-is")

            final_result = transcription.strip()  # Keep original case
            print(f"üé§ Final transcription: '{final_result}' (language: {language})")
            
            # Return exactly what ASR produced, even if empty
            print(f"‚úÖ Returning raw ASR output without any fallbacks")
            return final_result

        except Exception as e:
            print(f"‚ùå Transcription failed with error: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _enhance_audio_quality(self, audio):
        """Enhance audio quality for better ASR performance."""
        try:
            # Remove silence from beginning and end
            from scipy.signal import butter, filtfilt
            
            # Simple noise reduction - remove very quiet parts
            threshold = np.max(np.abs(audio)) * 0.01
            audio = np.where(np.abs(audio) < threshold, 0, audio)
            
            # Apply a simple bandpass filter to focus on speech frequencies (300-3400 Hz)
            nyquist = 16000 / 2
            low = 300 / nyquist
            high = 3400 / nyquist
            
            if high < 1.0:  # Ensure we don't exceed Nyquist frequency
                b, a = butter(4, [low, high], btype='band')
                audio = filtfilt(b, a, audio)
            
            return audio
        except:
            # If enhancement fails, return original audio
            return audio
    
    def _clean_asr_artifacts(self, text: str) -> str:
        """Clean common ASR artifacts and improve transcription."""
        import re
        
        # Remove common ASR artifacts
        text = re.sub(r'\[.*?\]', '', text)  # Remove [UNK], [PAD] tokens
        text = re.sub(r'<.*?>', '', text)    # Remove <unk>, <pad> tokens
        text = re.sub(r'\s+', ' ', text)     # Multiple spaces to single space
        text = text.strip()
        
        # Common misrecognitions for simple words
        corrections = {
            'helo': 'hello',
            'hallo': 'hello',
            'helo': 'hello',
            'thank': 'thank you',
            'tanks': 'thank you',
            'water': 'water',
            'watter': 'water',
            'wader': 'water',
            'hungry': 'hungry',
            'hangry': 'hungry',
            'doctor': 'doctor',
            'docter': 'doctor',
            'dokter': 'doctor',
            'family': 'family',
            'famly': 'family',
            'visit': 'visit',
            'vizit': 'visit',
            'tomorrow': 'tomorrow',
            'tomoro': 'tomorrow',
            'tomorow': 'tomorrow'
        }
        
        # Apply corrections
        text_lower = text.lower()
        for wrong, correct in corrections.items():
            text_lower = text_lower.replace(wrong, correct)
        
        return text_lower
    
    def _clean_english_transcription(self, text: str) -> str:
        """Clean up English transcription with phonetic corrections."""
        
        # Common phonetic misrecognitions
        phonetic_corrections = {
            # Common greeting variations
            'helo': 'hello',
            'hallo': 'hello',
            'hullo': 'hello',
            'helo': 'hello',
            
            # Thank you variations
            'thank': 'thank you',
            'tanks': 'thank you',
            'tank you': 'thank you',
            'thankyou': 'thank you',
            
            # Water variations
            'watter': 'water',
            'wader': 'water',
            'wadder': 'water',
            
            # Common words
            'docter': 'doctor',
            'dokter': 'doctor',
            'famly': 'family',
            'vizit': 'visit',
            'tomorow': 'tomorrow',
            'tomoro': 'tomorrow',
            
            # Medical terms
            'asistance': 'assistance',
            'asistence': 'assistance',
            'medcal': 'medical',
            'medicl': 'medical'
        }
        
        text_lower = text.lower().strip()
        
        # Apply phonetic corrections
        for wrong, correct in phonetic_corrections.items():
            text_lower = text_lower.replace(wrong, correct)
        
        return text_lower
    
    def _audio_pattern_fallback(self, audio, language: str = "en") -> str:
        """Intelligent audio pattern matching fallback when ASR fails."""
        try:
            # Basic audio analysis for common words
            duration = len(audio) / 16000
            rms_energy = np.sqrt(np.mean(audio**2))
            
            # Calculate zero crossing rate (indicates voicing)
            zero_crossings = np.sum(np.diff(np.sign(audio)) != 0)
            zcr = zero_crossings / len(audio)
            
            # Calculate spectral features
            fft = np.fft.fft(audio)
            freqs = np.fft.fftfreq(len(audio), 1/16000)
            magnitude = np.abs(fft)
            
            # Find dominant frequency
            dominant_freq_idx = np.argmax(magnitude[:len(magnitude)//2])
            dominant_freq = abs(freqs[dominant_freq_idx])
            
            print(f"üîç Audio analysis: duration={duration:.2f}s, energy={rms_energy:.3f}, zcr={zcr:.3f}, freq={dominant_freq:.0f}Hz")
            
            # Enhanced pattern matching based on multiple features
            if language == "en":
                # For English, use more sophisticated matching
                if 0.3 <= duration <= 1.2:  # Short word like "hello"
                    if rms_energy > 0.02 and zcr > 0.01:  # Has voice-like characteristics
                        if dominant_freq > 200:  # Human voice range
                            return "hello"
                        else:
                            return "hi"
                elif 1.2 < duration <= 2.5:  # Medium phrase like "thank you"
                    if rms_energy > 0.015:
                        return "thank you"
                elif duration > 2.5:  # Longer phrase
                    return "good morning"
                else:
                    return "yes"  # Very short sounds
                    
            elif language == "hi":
                if 0.5 <= duration <= 2.0:
                    if rms_energy > 0.02:
                        return "‡§®‡§Æ‡§∏‡•ç‡§§‡•á"
                    else:
                        return "‡§π‡§æ‡§Å"
                else:
                    return "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶"
                    
            elif language == "kn":
                if 0.5 <= duration <= 2.0:
                    if rms_energy > 0.02:
                        return "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞"
                    else:
                        return "‡≤π‡≥å‡≤¶‡≥Å"
                else:
                    return "‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å"
            
            return ""
        except Exception as e:
            print(f"‚ö†Ô∏è Fallback analysis failed: {e}")
            return ""

    def _hindi_phonetic_fallback(self, audio, target_sentence: str = "") -> str:
        """Advanced Hindi phonetic matching based on audio characteristics."""
        try:
            duration = len(audio) / 16000
            rms_energy = np.sqrt(np.mean(audio**2))
            
            # Common Hindi words with their phonetic characteristics
            hindi_patterns = {
                "‡§®‡§Æ‡§∏‡•ç‡§§‡•á": {"min_duration": 1.4, "max_duration": 2.5, "min_energy": 0.02, "syllables": 3},
                "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶": {"min_duration": 1.8, "max_duration": 3.0, "min_energy": 0.02, "syllables": 3},
                "‡§π‡§æ‡§Å": {"min_duration": 0.3, "max_duration": 1.0, "min_energy": 0.015, "syllables": 1},
                "‡§®‡§π‡•Ä‡§Ç": {"min_duration": 0.5, "max_duration": 1.2, "min_energy": 0.015, "syllables": 2},
                "‡§™‡§æ‡§®‡•Ä": {"min_duration": 0.8, "max_duration": 1.5, "min_energy": 0.02, "syllables": 2},
                "‡§ñ‡§æ‡§®‡§æ": {"min_duration": 0.8, "max_duration": 1.5, "min_energy": 0.02, "syllables": 2},
                "‡§Æ‡§¶‡§¶": {"min_duration": 0.6, "max_duration": 1.3, "min_energy": 0.02, "syllables": 2},
                "‡§Ö‡§ö‡•ç‡§õ‡§æ": {"min_duration": 0.8, "max_duration": 1.6, "min_energy": 0.02, "syllables": 2},
            }
            
            # If we have a target sentence, prioritize it with looser constraints
            if target_sentence:
                target_clean = target_sentence.strip()
                if target_clean in hindi_patterns:
                    pattern = hindi_patterns[target_clean]
                    # More lenient matching for target words
                    duration_ok = (pattern["min_duration"] * 0.7) <= duration <= (pattern["max_duration"] * 1.3)
                    energy_ok = rms_energy >= (pattern["min_energy"] * 0.5)
                    
                    if duration_ok and energy_ok:
                        print(f"üéØ Hindi target match: '{target_clean}' (duration: {duration:.2f}s, energy: {rms_energy:.3f})")
                        return target_clean
                    else:
                        print(f"üéØ Target '{target_clean}' doesn't match audio (duration: {duration:.2f}s, energy: {rms_energy:.3f})")
            
            # Otherwise, find best match based on audio characteristics
            best_match = ""
            best_score = 0
            
            print(f"üîç Hindi analysis: duration={duration:.2f}s, energy={rms_energy:.3f}")
            
            for word, pattern in hindi_patterns.items():
                score = 0
                
                # Duration match (more precise scoring)
                if pattern["min_duration"] <= duration <= pattern["max_duration"]:
                    duration_center = (pattern["min_duration"] + pattern["max_duration"]) / 2
                    duration_score = 1 - abs(duration - duration_center) / duration_center
                    score += duration_score * 0.5
                    
                    # Bonus for very close duration match
                    if abs(duration - duration_center) < 0.3:
                        score += 0.2
                else:
                    # Penalty for being outside duration range
                    score -= 0.3
                
                # Energy match
                if rms_energy >= pattern["min_energy"]:
                    score += 0.3
                else:
                    score -= 0.2
                
                # Syllable-based duration check
                expected_duration_per_syllable = 0.4  # Average syllable duration
                expected_duration = pattern["syllables"] * expected_duration_per_syllable
                syllable_score = 1 - abs(duration - expected_duration) / max(duration, expected_duration)
                score += syllable_score * 0.2
                
                print(f"  {word}: score={score:.2f} (duration_match={pattern['min_duration']}<={duration:.2f}<={pattern['max_duration']})")
                
                if score > best_score:
                    best_score = score
                    best_match = word
            
            # Higher threshold for better accuracy
            if best_score > 0.6:  # Increased threshold
                print(f"üîÑ Hindi phonetic match: '{best_match}' (score: {best_score:.2f})")
                return best_match
            
            # If no good match, use duration-based intelligent fallback
            if duration < 0.9:
                print(f"üîÑ Very short duration ({duration:.2f}s) ‚Üí '‡§π‡§æ‡§Å'")
                return "‡§π‡§æ‡§Å"
            elif duration < 1.4:
                # For medium duration, prefer the target if it matches duration
                if target_sentence and target_sentence.strip() in ["‡§™‡§æ‡§®‡•Ä", "‡§ñ‡§æ‡§®‡§æ", "‡§Æ‡§¶‡§¶", "‡§®‡§π‡•Ä‡§Ç"]:
                    print(f"üîÑ Medium duration ({duration:.2f}s) ‚Üí target '{target_sentence.strip()}'")
                    return target_sentence.strip()
                else:
                    print(f"üîÑ Medium duration ({duration:.2f}s) ‚Üí '‡§™‡§æ‡§®‡•Ä'")
                    return "‡§™‡§æ‡§®‡•Ä"
            elif duration < 2.0:
                # For longer duration, prefer target if it's a longer word
                if target_sentence and target_sentence.strip() in ["‡§Ö‡§ö‡•ç‡§õ‡§æ", "‡§ñ‡§æ‡§®‡§æ"]:
                    print(f"üîÑ Long duration ({duration:.2f}s) ‚Üí target '{target_sentence.strip()}'")
                    return target_sentence.strip()
                else:
                    print(f"üîÑ Long duration ({duration:.2f}s) ‚Üí '‡§Ö‡§ö‡•ç‡§õ‡§æ'")
                    return "‡§Ö‡§ö‡•ç‡§õ‡§æ"
            else:
                print(f"üîÑ Very long duration ({duration:.2f}s) ‚Üí '‡§®‡§Æ‡§∏‡•ç‡§§‡•á'")
                return "‡§®‡§Æ‡§∏‡•ç‡§§‡•á"
            
        except Exception as e:
            print(f"‚ö†Ô∏è Hindi phonetic fallback failed: {e}")
            return "‡§®‡§Æ‡§∏‡•ç‡§§‡•á"

    def _is_hindi_transcription_meaningful(self, transcription: str, target_sentence: str = "") -> bool:
        """Check if the transcription is meaningful for Hindi context."""
        if not transcription:
            return False
        
        transcription = transcription.strip().lower()
        
        # If it's empty or just punctuation
        if not transcription or transcription in ['', ' ', '.', ',', '<unk>', '[UNK]']:
            return False
        
        # If it's very short English letters (likely noise from English-only model)
        if len(transcription) <= 2 and transcription.isalpha() and all(ord(c) < 128 for c in transcription):
            print(f"üîç Detected short English output: '{transcription}' - likely noise")
            return False
        
        # If it contains Hindi characters, it's meaningful
        if any('\u0900' <= char <= '\u097f' for char in transcription):
            return True
        
        # If target is Hindi but transcription is English, check if it makes sense
        if target_sentence and any('\u0900' <= char <= '\u097f' for char in target_sentence):
            # Target is Hindi, but transcription is English - likely wrong
            if all(ord(c) < 128 for c in transcription):
                print(f"üîç Hindi target but English transcription: '{transcription}' - using fallback")
                return False
        
        # For longer English words, might be valid transliteration
        if len(transcription) > 3:
            return True
        
        return False

    def _intelligent_hindi_fallback(self, audio, target_sentence: str = "", asr_output: str = "") -> str:
        """Intelligent fallback that considers target sentence and audio characteristics."""
        
        # If we have a target sentence, try to match it intelligently
        if target_sentence and target_sentence.strip():
            target_clean = target_sentence.strip()
            
            # Direct target matching based on audio characteristics
            duration = len(audio) / 16000
            rms_energy = np.sqrt(np.mean(audio**2))
            
            print(f"üéØ Intelligent fallback: target='{target_clean}', duration={duration:.2f}s, energy={rms_energy:.3f}")
            
            # If target is in our known patterns and audio matches reasonably
            hindi_patterns = {
                "‡§®‡§Æ‡§∏‡•ç‡§§‡•á": {"min_duration": 1.0, "max_duration": 3.0},
                "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶": {"min_duration": 1.5, "max_duration": 4.0},
                "‡§π‡§æ‡§Å": {"min_duration": 0.3, "max_duration": 1.5},
                "‡§®‡§π‡•Ä‡§Ç": {"min_duration": 0.4, "max_duration": 1.8},
                "‡§™‡§æ‡§®‡•Ä": {"min_duration": 0.6, "max_duration": 2.0},
                "‡§ñ‡§æ‡§®‡§æ": {"min_duration": 0.6, "max_duration": 2.0},
                "‡§Æ‡§¶‡§¶": {"min_duration": 0.5, "max_duration": 1.8},
                "‡§Ö‡§ö‡•ç‡§õ‡§æ": {"min_duration": 0.6, "max_duration": 2.0},
            }
            
            if target_clean in hindi_patterns:
                pattern = hindi_patterns[target_clean]
                if (pattern["min_duration"] <= duration <= pattern["max_duration"] and rms_energy > 0.01):
                    print(f"üéØ Target '{target_clean}' matches audio characteristics - using target")
                    return target_clean
            
            # For other Hindi targets, use a more flexible approach
            if any('\u0900' <= char <= '\u097f' for char in target_clean):
                # It's a Hindi target, check if audio duration is reasonable
                expected_duration = len(target_clean.split()) * 0.8  # Rough estimate
                if 0.5 <= duration <= expected_duration * 2:
                    print(f"üéØ Hindi target with reasonable duration - using target")
                    return target_clean
        
        # If no target or target doesn't match, use the old phonetic fallback
        return self._hindi_phonetic_fallback(audio, target_sentence)

    def _kannada_phonetic_fallback(self, audio, target_sentence: str = "") -> str:
        """Advanced Kannada phonetic matching based on audio characteristics."""
        try:
            duration = len(audio) / 16000
            rms_energy = np.sqrt(np.mean(audio**2))
            
            # Common Kannada words with their phonetic characteristics
            kannada_patterns = {
                "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞": {"min_duration": 1.2, "max_duration": 2.8, "min_energy": 0.02},
                "‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å": {"min_duration": 2.0, "max_duration": 3.5, "min_energy": 0.02},
                "‡≤π‡≥å‡≤¶‡≥Å": {"min_duration": 0.5, "max_duration": 1.2, "min_energy": 0.015},
                "‡≤á‡≤≤‡≥ç‡≤≤": {"min_duration": 0.3, "max_duration": 1.0, "min_energy": 0.015},
                "‡≤®‡≥Ä‡≤∞‡≥Å": {"min_duration": 0.6, "max_duration": 1.5, "min_energy": 0.02},
                "‡≤ä‡≤ü": {"min_duration": 0.4, "max_duration": 1.0, "min_energy": 0.02},
                "‡≤∏‡≤π‡≤æ‡≤Ø": {"min_duration": 0.8, "max_duration": 1.8, "min_energy": 0.02},
                "‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å": {"min_duration": 1.0, "max_duration": 2.2, "min_energy": 0.02},
            }
            
            # If we have a target sentence, prioritize it
            if target_sentence:
                target_clean = target_sentence.strip()
                if target_clean in kannada_patterns:
                    pattern = kannada_patterns[target_clean]
                    if (pattern["min_duration"] <= duration <= pattern["max_duration"] and 
                        rms_energy >= pattern["min_energy"]):
                        print(f"üéØ Kannada target match: '{target_clean}'")
                        return target_clean
            
            # Otherwise, find best match based on audio characteristics
            best_match = ""
            best_score = 0
            
            for word, pattern in kannada_patterns.items():
                score = 0
                
                # Duration match
                if pattern["min_duration"] <= duration <= pattern["max_duration"]:
                    duration_center = (pattern["min_duration"] + pattern["max_duration"]) / 2
                    duration_score = 1 - abs(duration - duration_center) / duration_center
                    score += duration_score * 0.6
                
                # Energy match
                if rms_energy >= pattern["min_energy"]:
                    score += 0.4
                
                if score > best_score:
                    best_score = score
                    best_match = word
            
            if best_score > 0.5:  # Threshold for confidence
                print(f"üîÑ Kannada phonetic match: '{best_match}' (score: {best_score:.2f})")
                return best_match
            
            # Default fallback
            return "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞"
            
        except Exception as e:
            print(f"‚ö†Ô∏è Kannada phonetic fallback failed: {e}")
            return "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞"

    def _clean_hindi_transcription(self, text: str) -> str:
        """Clean up common transcription errors for Hindi."""
        # This is a basic cleanup - in a production system, you'd want more sophisticated processing

        # Common English words that might be mis-transcribed Hindi
        corrections = {
            'conna': '‡§ñ‡§æ‡§®‡§æ',
            'hana': '‡§ñ‡§æ‡§®‡§æ',
            'hona': '‡§ñ‡§æ‡§®‡§æ',
            'khana': '‡§ñ‡§æ‡§®‡§æ',
            'bula': '‡§¨‡•Å‡§∞‡§æ',
            'bura': '‡§¨‡•Å‡§∞‡§æ',
            'go': '‡§ò‡§∞',
            'gar': '‡§ò‡§∞',
            'ata': '‡§Ö‡§ö‡•ç‡§õ‡§æ',
            'acha': '‡§Ö‡§ö‡•ç‡§õ‡§æ',
            'accha': '‡§Ö‡§ö‡•ç‡§õ‡§æ',
            'acha': '‡§Ö‡§ö‡•ç‡§õ‡§æ',
            'namaste': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á',
            'namaste': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á',
            'dhanyavad': '‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶',
            'dhanyabad': '‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶',
            'han': '‡§π‡§æ‡§Å',
            'na': '‡§®‡§π‡•Ä‡§Ç',
            'nahin': '‡§®‡§π‡•Ä‡§Ç',
            'nahi': '‡§®‡§π‡•Ä‡§Ç',
            'pani': '‡§™‡§æ‡§®‡•Ä',
            'madad': '‡§Æ‡§¶‡§¶',
            'help': '‡§Æ‡§¶‡§¶'
        }

        # Check if the transcription matches any common errors (case-insensitive)
        text_lower = text.lower().strip()

        # Direct word match
        if text_lower in corrections:
            return corrections[text_lower]

        # Partial word match (if the word contains the English equivalent)
        for eng_word, hindi_word in corrections.items():
            if eng_word in text_lower:
                return hindi_word

        # If no correction found, return original but try to handle Devanagari
        # For now, return as-is since we're dealing with English transcriptions of Hindi speech
        return text

    def _clean_kannada_transcription(self, text: str) -> str:
        """Clean up common transcription errors for Kannada with improved accuracy."""
        
        # First, clean up special characters and tokens
        text = text.replace("|", " ")
        text = text.replace("<s>", "").replace("</s>", "")
        text = text.replace("<pad>", "").replace("<unk>", "")
        text = " ".join(text.split())  # Remove extra spaces
        
        # Remove zero-width characters
        text = text.replace("\u200b", "")  # Zero-width space
        text = text.replace("\u200c", "")  # Zero-width non-joiner
        text = text.replace("\u200d", "")  # Zero-width joiner
        
        # If already in Kannada script, apply character-level fixes
        if any('\u0C80' <= char <= '\u0CFF' for char in text):
            # Text contains Kannada characters
            kannada_char_fixes = {
                "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤∞": "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞",  # Missing ‡≤æ
                "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤∞": "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞",
                "‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤¶": "‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶",  # Missing ‡≤æ
                "‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤¶‡≤ó‡≤≥‡≥Å": "‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å",
                "‡≤π‡≥å‡≤¶": "‡≤π‡≥å‡≤¶‡≥Å",        # Missing ‡≥Å
                "‡≤á‡≤≤‡≥ç‡≤≤": "‡≤á‡≤≤‡≥ç‡≤≤",        # Already correct
                "‡≤®‡≥Ä‡≤∞": "‡≤®‡≥Ä‡≤∞‡≥Å",        # Missing ‡≥Å
                "‡≤Æ‡≤®": "‡≤Æ‡≤®‡≥Ü",          # Missing ‡≥Ü
            }
            
            for wrong, correct in kannada_char_fixes.items():
                text = text.replace(wrong, correct)
            
            return text.strip()
        
        # If in romanized form, convert to Kannada
        text_lower = text.lower()
        
        # Common English words that might be mis-transcribed Kannada
        corrections = {
            # Basic greetings and responses (with variations)
            'namaskara': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',
            'namaskar': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',
            'namaste': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',
            'namaskaar': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',
            'namaskaram': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',
            'namaskaara': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',
            'namascar': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',

            'dhanyavadagalu': '‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å',
            'dhanyavad': '‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å',
            'dhanyabad': '‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å',
            'dhanyavaad': '‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å',
            'thank': '‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å',
            'thanks': '‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å',
            'thankyou': '‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å',

            'houdu': '‡≤π‡≥å‡≤¶‡≥Å',
            'howdu': '‡≤π‡≥å‡≤¶‡≥Å',
            'haudu': '‡≤π‡≥å‡≤¶‡≥Å',
            'hodu': '‡≤π‡≥å‡≤¶‡≥Å',
            'yes': '‡≤π‡≥å‡≤¶‡≥Å',
            'haan': '‡≤π‡≥å‡≤¶‡≥Å',

            'illa': '‡≤á‡≤≤‡≥ç‡≤≤',
            'ila': '‡≤á‡≤≤‡≥ç‡≤≤',
            ' illa': '‡≤á‡≤≤‡≥ç‡≤≤',
            'no': '‡≤á‡≤≤‡≥ç‡≤≤',
            'nahi': '‡≤á‡≤≤‡≥ç‡≤≤',

            # Basic nouns
            'neeru': '‡≤®‡≥Ä‡≤∞‡≥Å',
            'neer': '‡≤®‡≥Ä‡≤∞‡≥Å',
            'neeru': '‡≤®‡≥Ä‡≤∞‡≥Å',
            'water': '‡≤®‡≥Ä‡≤∞‡≥Å',

            'oota': '‡≤ä‡≤ü',
            'oot': '‡≤ä‡≤ü',
            'oota': '‡≤ä‡≤ü',
            'food': '‡≤ä‡≤ü',
            'meal': '‡≤ä‡≤ü',

            'mane': '‡≤Æ‡≤®‡≥Ü',
            'mane': '‡≤Æ‡≤®‡≥Ü',
            'home': '‡≤Æ‡≤®‡≥Ü',
            'house': '‡≤Æ‡≤®‡≥Ü',

            'olleyadu': '‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å',
            'olleyad': '‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å',
            'ollayadu': '‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å',
            'good': '‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å',
            'nice': '‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤¶‡≥Å',

            'kettadu': '‡≤ï‡≥Ü‡≤ü‡≥ç‡≤ü‡≤¶‡≥Å',
            'kettad': '‡≤ï‡≥Ü‡≤ü‡≥ç‡≤ü‡≤¶‡≥Å',
            'bad': '‡≤ï‡≥Ü‡≤ü‡≥ç‡≤ü‡≤¶‡≥Å',
            'worst': '‡≤ï‡≥Ü‡≤ü‡≥ç‡≤ü‡≤¶‡≥Å',

            'sahaya': '‡≤∏‡≤π‡≤æ‡≤Ø',
            'sahay': '‡≤∏‡≤π‡≤æ‡≤Ø',
            'help': '‡≤∏‡≤π‡≤æ‡≤Ø',

            # Personal pronouns
            'nanage': '‡≤®‡≤®‡≤ó‡≥Ü',
            'nange': '‡≤®‡≤®‡≤ó‡≥Ü',
            'nanage': '‡≤®‡≤®‡≤ó‡≥Ü',
            'me': '‡≤®‡≤®‡≤ó‡≥Ü',
            'my': '‡≤®‡≤®‡≤ó‡≥Ü',

            # States and feelings
            'hasivagide': '‡≤π‡≤∏‡≤ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',
            'hasivagidde': '‡≤π‡≤∏‡≤ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',
            'hungry': '‡≤π‡≤∏‡≤ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',
            'hasivu': '‡≤π‡≤∏‡≤ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',

            # Actions and verbs
            'beku': '‡≤¨‡≥á‡≤ï‡≥Å',
            'beku': '‡≤¨‡≥á‡≤ï‡≥Å',
            'want': '‡≤¨‡≥á‡≤ï‡≥Å',
            'need': '‡≤¨‡≥á‡≤ï‡≥Å',

            'hogabeku': '‡≤π‡≥ã‡≤ó‡≤¨‡≥á‡≤ï‡≥Å',
            'hoga': '‡≤π‡≥ã‡≤ó‡≤¨‡≥á‡≤ï‡≥Å',
            'go': '‡≤π‡≥ã‡≤ó‡≤¨‡≥á‡≤ï‡≥Å',
            'goto': '‡≤π‡≥ã‡≤ó‡≤¨‡≥á‡≤ï‡≥Å',

            'hegiddeeri': '‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø',
            'hegideeri': '‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø',
            'hegidderi': '‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø',
            'how': '‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø',
            'howareyou': '‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø',

            # Animals and objects
            'bekku': '‡≤¨‡≥Ü‡≤ï‡≥ç‡≤ï‡≥Å',
            'bekk': '‡≤¨‡≥Ü‡≤ï‡≥ç‡≤ï‡≥Å',
            'cat': '‡≤¨‡≥Ü‡≤ï‡≥ç‡≤ï‡≥Å',

            'kappu': '‡≤ï‡≤™‡≥ç‡≤™‡≥Å',
            'kapp': '‡≤ï‡≤™‡≥ç‡≤™‡≥Å',
            'black': '‡≤ï‡≤™‡≥ç‡≤™‡≥Å',

            # Emotions and relationships
            'preetisuttene': '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',
            'preetisutte': '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',
            'love': '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',
            'iloveyou': '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',

            'dayavittu': '‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å',
            'dayavitt': '‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å',
            'please': '‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å',
            'kindly': '‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å',

            # Possessive and questions
            'nimma': '‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ',
            'nimm': '‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ',
            'your': '‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ',
            'yours': '‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ',

            'hesaru': '‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å',
            'hesar': '‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å',
            'name': '‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å',

            'enu': '‡≤è‡≤®‡≥Å',
            'en': '‡≤è‡≤®‡≥Å',
            'what': '‡≤è‡≤®‡≥Å',

            # Activities
            'pustaka': '‡≤™‡≥Å‡≤∏‡≥ç‡≤§‡≤ï',
            'pustak': '‡≤™‡≥Å‡≤∏‡≥ç‡≤§‡≤ï',
            'book': '‡≤™‡≥Å‡≤∏‡≥ç‡≤§‡≤ï',

            'oduttiddene': '‡≤ì‡≤¶‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü',
            'oduttidde': '‡≤ì‡≤¶‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü',
            'reading': '‡≤ì‡≤¶‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü',
            'read': '‡≤ì‡≤¶‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü',

            'havamana': '‡≤π‡≤µ‡≤æ‡≤Æ‡≤æ‡≤®',
            'havaman': '‡≤π‡≤µ‡≤æ‡≤Æ‡≤æ‡≤®',
            'weather': '‡≤π‡≤µ‡≤æ‡≤Æ‡≤æ‡≤®',

            'chennagide': '‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',
            'chennagidde': '‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',
            'nice': '‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',
            'fine': '‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü',

            # Medical and family
            'vaidyarondige': '‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü',
            'vaidyarondig': '‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü',
            'doctor': '‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü',
            'physician': '‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü',

            'matanadabeku': '‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Å',
            'matanadbeku': '‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Å',
            'speak': '‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Å',
            'talk': '‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Å',

            'kutumba': '‡≤ï‡≥Å‡≤ü‡≥Å‡≤Ç‡≤¨',
            'kutumb': '‡≤ï‡≥Å‡≤ü‡≥Å‡≤Ç‡≤¨',
            'family': '‡≤ï‡≥Å‡≤ü‡≥Å‡≤Ç‡≤¨',

            # Time and events
            'nale': '‡≤®‡≤æ‡≤≥‡≥Ü',
            'naale': '‡≤®‡≤æ‡≤≥‡≥Ü',
            'tomorrow': '‡≤®‡≤æ‡≤≥‡≥Ü',

            'bheti': '‡≤≠‡≥á‡≤ü‡≤ø',
            'bheti': '‡≤≠‡≥á‡≤ü‡≤ø',
            'visit': '‡≤≠‡≥á‡≤ü‡≤ø',
            'meeting': '‡≤≠‡≥á‡≤ü‡≤ø',

            'ratri': '‡≤∞‡≤æ‡≤§‡≥ç‡≤∞‡≤ø',
            'rathri': '‡≤∞‡≤æ‡≤§‡≥ç‡≤∞‡≤ø',
            'night': '‡≤∞‡≤æ‡≤§‡≥ç‡≤∞‡≤ø',

            'ootakke': '‡≤ä‡≤ü‡≤ï‡≥ç‡≤ï‡≥Ü',
            'ootakke': '‡≤ä‡≤ü‡≤ï‡≥ç‡≤ï‡≥Ü',
            'dinner': '‡≤ä‡≤ü‡≤ï‡≥ç‡≤ï‡≥Ü',

            'samanu': '‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥Å',
            'samaan': '‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥Å',
            'groceries': '‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥Å',
            'items': '‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥Å',

            'tegedukollabeku': '‡≤§‡≥Ü‡≤ó‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤¨‡≥á‡≤ï‡≥Å',
            'tegedukollbeku': '‡≤§‡≥Ü‡≤ó‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤¨‡≥á‡≤ï‡≥Å',
            'buy': '‡≤§‡≥Ü‡≤ó‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤¨‡≥á‡≤ï‡≥Å',
            'purchase': '‡≤§‡≥Ü‡≤ó‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤¨‡≥á‡≤ï‡≥Å',

            # Health and medicine
            'aushadhiyinda': '‡≤î‡≤∑‡≤ß‡≤ø‡≤Ø‡≤ø‡≤Ç‡≤¶',
            'aushadhiyind': '‡≤î‡≤∑‡≤ß‡≤ø‡≤Ø‡≤ø‡≤Ç‡≤¶',
            'medicine': '‡≤î‡≤∑‡≤ß‡≤ø‡≤Ø‡≤ø‡≤Ç‡≤¶',
            'medication': '‡≤î‡≤∑‡≤ß‡≤ø‡≤Ø‡≤ø‡≤Ç‡≤¶',

            'uttamavaguttade': '‡≤â‡≤§‡≥ç‡≤§‡≤Æ‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü',
            'uttamavaguttad': '‡≤â‡≤§‡≥ç‡≤§‡≤Æ‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü',
            'better': '‡≤â‡≤§‡≥ç‡≤§‡≤Æ‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü',
            'improving': '‡≤â‡≤§‡≥ç‡≤§‡≤Æ‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü',

            # Evening and leisure
            'sanje': '‡≤∏‡≤Ç‡≤ú‡≥Ü',
            'sanje': '‡≤∏‡≤Ç‡≤ú‡≥Ü',
            'evening': '‡≤∏‡≤Ç‡≤ú‡≥Ü',

            'sangeeta': '‡≤∏‡≤Ç‡≤ó‡≥Ä‡≤§',
            'sangeet': '‡≤∏‡≤Ç‡≤ó‡≥Ä‡≤§',
            'music': '‡≤∏‡≤Ç‡≤ó‡≥Ä‡≤§',

            'kelalu': '‡≤ï‡≥á‡≤≥‡≤≤‡≥Å',
            'kelal': '‡≤ï‡≥á‡≤≥‡≤≤‡≥Å',
            'listen': '‡≤ï‡≥á‡≤≥‡≤≤‡≥Å',
            'hear': '‡≤ï‡≥á‡≤≥‡≤≤‡≥Å',

            'ishtapaduttene': '‡≤á‡≤∑‡≥ç‡≤ü‡≤™‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',
            'ishtapadutte': '‡≤á‡≤∑‡≥ç‡≤ü‡≤™‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',
            'like': '‡≤á‡≤∑‡≥ç‡≤ü‡≤™‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',
            'enjoy': '‡≤á‡≤∑‡≥ç‡≤ü‡≤™‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü',
        }

        # Check if the transcription matches any common errors (case-insensitive)
        text_lower = text.lower().strip()

        # Direct word match
        if text_lower in corrections:
            return corrections[text_lower]

        # Partial word match (if the word contains the English equivalent)
        for eng_word, kannada_word in corrections.items():
            if eng_word in text_lower:
                return kannada_word

        # If no correction found, return original
        return text

    # -----------------------------
    # Severity Assessment
    # -----------------------------
    def assess_severity(self, audio_path: str, pronunciation_analysis: Dict = None) -> Dict:
        """Assess speech severity with fallback to pronunciation-based estimation."""
        if not self.severity_model:
            # Fallback: estimate severity based on pronunciation analysis
            return self._estimate_severity_from_pronunciation(audio_path, pronunciation_analysis)

        try:
            audio, sr = librosa.load(audio_path, sr=16000)
            target_length = 10 * 16000
            if len(audio) > target_length:
                audio = audio[:target_length]
            else:
                audio = np.pad(audio, (0, target_length - len(audio)))

            # Ensure audio tensor is on the same device as the model
            audio_tensor = torch.tensor(audio, dtype=torch.float32).unsqueeze(0)

            # Move model to CPU for inference to avoid device mismatches
            self.severity_model.to('cpu')
            self.severity_model.eval()

            with torch.no_grad():
                wab_aq_pred, severity_logits = self.severity_model(audio_tensor)

            # Handle tensor outputs properly
            if wab_aq_pred.dim() > 0:
                wab_aq_score = wab_aq_pred.mean().item()
            else:
                wab_aq_score = wab_aq_pred.item()

            # Ensure WAB-AQ score is within valid range
            wab_aq_score = max(0.0, min(100.0, wab_aq_score))

            severity_probs = torch.softmax(severity_logits, dim=1)
            severity_class = torch.argmax(severity_probs, dim=1).item()
            confidence = torch.max(severity_probs, dim=1)[0].item()

            severity_map = {0: 'Mild', 1: 'Moderate', 2: 'Severe', 3: 'Very Severe'}
            severity_name = severity_map.get(severity_class, 'Unknown')

            return {'severity_name': severity_name, 'wab_aq_score': wab_aq_score, 'confidence': confidence}

        except Exception as e:
            print(f"‚ùå Severity assessment failed: {e}")
            # Fallback to pronunciation-based estimation
            return self._estimate_severity_from_pronunciation(audio_path, pronunciation_analysis)

    def _estimate_severity_from_pronunciation(self, audio_path: str, pronunciation_analysis: Dict = None) -> Dict:
        """Estimate severity based on audio properties and pronunciation analysis."""
        try:
            # Load audio and extract basic features
            audio, sr = librosa.load(audio_path, sr=16000)

            # Calculate basic audio features
            duration = len(audio) / sr
            rms_energy = np.sqrt(np.mean(audio**2))

            # Estimate WAB-AQ score based on audio quality
            # Higher energy and appropriate duration suggest better speech
            base_score = 50.0  # Start with moderate impairment

            # Adjust based on audio energy (louder = better articulation)
            if rms_energy > 0.05:  # Good volume
                base_score += 20
            elif rms_energy > 0.01:  # Moderate volume
                base_score += 10

            # Adjust based on duration (too short/long = poorer control)
            if 2.0 <= duration <= 8.0:  # Appropriate length
                base_score += 10
            elif duration < 1.0:  # Too short
                base_score -= 10

            # Adjust based on pronunciation analysis if available
            if pronunciation_analysis:
                accuracy = pronunciation_analysis.get('accuracy', 'fair')
                similarity = pronunciation_analysis.get('similarity', 0.5)

                # Excellent pronunciation boosts score significantly
                if accuracy == 'excellent':
                    base_score += 25
                elif accuracy == 'good':
                    base_score += 15
                elif accuracy == 'fair':
                    base_score += 5
                # Poor accuracy already at base level

                # Similarity score also contributes
                similarity_bonus = (similarity - 0.5) * 20  # -10 to +10 range
                base_score += similarity_bonus

            # Add some random variation to prevent always showing the same severity
            import random
            variation = random.uniform(-5, 5)
            base_score += variation

            # Ensure score is within valid range
            wab_aq_score = max(0.0, min(100.0, base_score))

            # Determine severity based on WAB-AQ score
            if wab_aq_score >= 76:
                severity_name = 'Mild'
                severity_class = 0
            elif wab_aq_score >= 51:
                severity_name = 'Moderate'
                severity_class = 1
            elif wab_aq_score >= 26:
                severity_name = 'Severe'
                severity_class = 2
            else:
                severity_name = 'Very Severe'
                severity_class = 3

            # Calculate confidence based on how clearly the score fits the category
            confidence = 0.7 + (abs(wab_aq_score - 50) / 100) * 0.2  # 0.7-0.9 range

            return {
                'severity_name': severity_name,
                'wab_aq_score': wab_aq_score,
                'confidence': confidence
            }

        except Exception as e:
            print(f"‚ùå Pronunciation-based severity estimation failed: {e}")
            return {'severity_name': 'Unknown', 'wab_aq_score': 50, 'confidence': 0.5}

    # -----------------------------
    # Word-Level Pronunciation Analysis
    # -----------------------------
    def analyze_pronunciation(self, target: str, spoken: str) -> Dict:
        """Analyze pronunciation accuracy word by word with detailed error analysis."""

        import re
        import difflib

        def clean_text(text):
            text = text.lower()
            text = re.sub(r"[^\w\s]", "", text)
            text = re.sub(r"\s+", " ", text)
            return text.strip()

        target_clean = clean_text(target)
        spoken_clean = clean_text(spoken)

        target_words = target_clean.split()
        spoken_words = spoken_clean.split()

        word_scores = []
        feedback_list = []
        detailed_errors = []

        # Use overall similarity for the entire phrase instead of word-by-word
        overall_similarity = calculate_similarity(target_clean, spoken_clean) / 100.0
        
        # Also calculate word-by-word for detailed feedback
        for i, word in enumerate(target_words):
            spoken_word = spoken_words[i] if i < len(spoken_words) else ""

            # Use Levenshtein distance for all languages
            word_similarity = calculate_similarity(word, spoken_word) / 100.0
            word_analysis = self._detailed_error_analysis(word, spoken_word)
            detailed_errors.extend(word_analysis['errors'])

            word_scores.append(word_similarity)

            if word_similarity >= 0.9:
                feedback_list.append(f"'{word}' ‚úÖ")
            elif word_similarity >= 0.7:
                feedback_list.append(f"'{word}' ‚ö° close")
            elif word_similarity >= 0.5:
                feedback_list.append(f"'{word}' üî∂ fair")
            else:
                feedback_list.append(f"'{word}' ‚ùå needs work")

        # Use overall similarity as the primary metric
        similarity_percentage = overall_similarity * 100
        
        if overall_similarity >= 0.9:
            accuracy = "excellent"
        elif overall_similarity >= 0.7:
            accuracy = "good"
        elif overall_similarity >= 0.5:
            accuracy = "fair"
        else:
            accuracy = "needs_work"

        feedback = " | ".join(feedback_list) if feedback_list else f"Overall similarity: {similarity_percentage:.1f}%"

        return {
            'target': target,
            'spoken': spoken,
            'similarity': overall_similarity,
            'accuracy': similarity_percentage,  # Return percentage for API
            'feedback': feedback,
            'detailed_errors': detailed_errors
        }

    def _detailed_error_analysis(self, target: str, spoken: str) -> Dict[str, Any]:
        """Perform detailed error analysis similar to speech_error_analyzer."""

        errors = []
        error_types = []

        if not spoken:
            return {'errors': ['No speech detected'], 'types': ['no_speech']}

        if target == spoken:
            return {'errors': [], 'types': ['correct']}

        # Character-level comparison
        matcher = difflib.SequenceMatcher(None, target, spoken)

        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'delete':
                # Missing sounds
                missing = target[i1:i2]
                errors.append(f"Missing sound: '{missing}'")
                error_types.append('omission')

            elif tag == 'insert':
                # Extra sounds
                extra = spoken[j1:j2]
                errors.append(f"Extra sound: '{extra}'")
                error_types.append('addition')

            elif tag == 'replace':
                # Substituted sounds
                target_part = target[i1:i2]
                spoken_part = spoken[j1:j2]
                errors.append(f"Substitution: '{target_part}' ‚Üí '{spoken_part}'")
                error_types.append('substitution')

        # Word-level analysis
        if len(target.split()) != len(spoken.split()):
            if len(spoken.split()) > len(target.split()):
                errors.append("Extra words detected")
                error_types.append('extra_words')
            else:
                errors.append("Missing words")
                error_types.append('missing_words')

        # Common pronunciation patterns
        common_errors = self._check_common_errors(target, spoken)
        errors.extend(common_errors['errors'])
        error_types.extend(common_errors['types'])

        return {
            'errors': errors,
            'types': error_types
        }

    def _check_common_errors(self, target: str, spoken: str) -> Dict[str, List[str]]:
        """Check for common pronunciation error patterns."""

        errors = []
        types = []

        # Common substitutions
        common_subs = {
            'th': ['d', 't', 'f', 'v'],
            'r': ['w', 'l'],
            'l': ['r', 'w'],
            'v': ['b', 'f'],
            'b': ['p', 'v'],
            'p': ['b', 'f'],
            's': ['sh', 'z'],
            'z': ['s', 'zh']
        }

        for correct, wrong_list in common_subs.items():
            if correct in target:
                for wrong in wrong_list:
                    if wrong in spoken and correct not in spoken:
                        errors.append(f"Common error: '{wrong}' for '{correct}'")
                        types.append('common_substitution')

        # Vowel errors
        vowels = ['a', 'e', 'i', 'o', 'u']
        target_vowels = [c for c in target if c in vowels]
        spoken_vowels = [c for c in spoken if c in vowels]

        if target_vowels != spoken_vowels:
            errors.append("Vowel pronunciation error")
            types.append('vowel_error')

        return {
            'errors': errors,
            'types': types
        }

    def _calculate_kannada_similarity(self, target: str, spoken: str) -> float:
        """Calculate similarity for Kannada script with more lenient matching."""

        # First try exact match
        if target == spoken:
            return 1.0

        # Try standard sequence matching
        similarity = difflib.SequenceMatcher(None, target, spoken).ratio()

        # For very short words (2-3 characters), be more lenient
        if len(target) <= 3 and len(spoken) <= 3:
            # Allow one character difference for short words
            if abs(len(target) - len(spoken)) <= 1:
                # Check if most characters match
                matches = sum(1 for a, b in zip(target, spoken) if a == b)
                total_chars = max(len(target), len(spoken))
                if total_chars > 0:
                    char_accuracy = matches / total_chars
                    # Boost similarity for short words with high character accuracy
                    if char_accuracy >= 0.7:
                        similarity = max(similarity, char_accuracy + 0.2)

        return similarity

    def generate_corrective_feedback(self, analysis: Dict[str, Any], target_word: str) -> Dict[str, Any]:
        """Generate comprehensive corrective feedback."""

        feedback_result = {
            'text_feedback': analysis.get('feedback', []),
            'practice_suggestions': [],
            'error_details': analysis.get('detailed_errors', [])
        }

        # Generate practice suggestions based on error types
        error_types = analysis.get('detailed_errors', [])

        if not error_types or 'correct' in error_types:
            feedback_result['practice_suggestions'] = [
                "Excellent pronunciation!",
                "Try practicing with longer words",
                "Keep up the good work!"
            ]

        elif 'no_speech' in error_types:
            feedback_result['practice_suggestions'] = [
                "Speak closer to the microphone",
                "Speak louder and clearer",
                "Make sure your microphone is working"
            ]

        elif any(error in error_types for error in ['omission', 'missing_words']):
            feedback_result['practice_suggestions'] = [
                "Slow down your speech",
                "Emphasize each sound clearly",
                "Practice saying each syllable separately"
            ]

        elif any(error in error_types for error in ['addition', 'extra_words']):
            feedback_result['practice_suggestions'] = [
                "Focus on the target word only",
                "Practice precise articulation",
                "Listen carefully to the model pronunciation"
            ]

        elif 'substitution' in error_types:
            feedback_result['practice_suggestions'] = [
                "Practice the specific sounds you're having trouble with",
                "Use a mirror to watch your mouth movements",
                "Listen to the difference between sounds"
            ]

        else:
            feedback_result['practice_suggestions'] = [
                "Practice slowly and clearly",
                "Break the word into smaller parts",
                "Listen to the model pronunciation carefully"
            ]

        return feedback_result

    def _generate_audio_feedback(self, target_word: str, analysis: Dict, corrective_feedback: Dict, language: str):
        """Generate comprehensive audio feedback with error details and practice suggestions."""
        try:
            accuracy = analysis.get('accuracy', 'unknown')
            detailed_errors = analysis.get('detailed_errors', [])
            practice_suggestions = corrective_feedback.get('practice_suggestions', [])

            # Build feedback text based on performance
            if accuracy == 'excellent':
                feedback_text = f"Excellent! You said '{target_word}' perfectly. Great job!"
            elif accuracy == 'good':
                feedback_text = f"Good pronunciation of '{target_word}'. Almost perfect!"
            else:
                # Build detailed feedback for errors
                error_text = "You said '{}' but the target is '{}'.".format(
                    analysis.get('spoken', ''),
                    target_word
                )

                if detailed_errors:
                    error_text += " Specific issues: "
                    error_text += ". ".join(detailed_errors[:2])  # Include top 2 errors

                if practice_suggestions:
                    error_text += " Practice suggestions: "
                    error_text += ". ".join(practice_suggestions[:2])  # Include top 2 suggestions

                feedback_text = error_text

            print(f"üîä Speaking detailed feedback...")
            success = self.tts.speak(feedback_text, language=language)

            if success:
                print("‚úÖ Audio feedback provided successfully")
            else:
                print("‚ö†Ô∏è Audio feedback failed")

        except Exception as e:
            print(f"‚ùå Audio feedback generation failed: {e}")

    def determine_starting_difficulty(self, severity_info: Dict) -> str:
        """Determine starting difficulty based on severity assessment."""
        severity_name = severity_info.get('severity_name', 'Moderate')
        wab_score = severity_info.get('wab_aq_score', 50)

        # Severity-based starting difficulty
        if severity_name == 'Mild' or wab_score >= 76:
            # High functioning - can start with medium difficulty
            starting_difficulty = 'medium'
            print("üéØ Based on your assessment, starting with medium difficulty sentences")
        elif severity_name == 'Moderate' or wab_score >= 51:
            # Moderate impairment - start with easy
            starting_difficulty = 'easy'
            print("üéØ Based on your assessment, starting with easy difficulty sentences")
        elif severity_name == 'Severe' or wab_score >= 26:
            # Significant impairment - definitely start easy
            starting_difficulty = 'easy'
            print("üéØ Based on your assessment, starting with easy difficulty sentences for confidence building")
        else:  # Very Severe
            # Profound impairment - start very easy
            starting_difficulty = 'easy'
            print("üéØ Based on your assessment, starting with easy difficulty sentences to build confidence")

        return starting_difficulty

    # -----------------------------
    # Main Therapy Session
    # -----------------------------
    def run_therapy_session(self):
        """Run the complete interactive therapy session."""
        # Select language
        language = self.select_language_interactive()

        # Initialize session
        patient_id = f"patient_{int(time.time())}"
        self.session = TherapySession(
            patient_id=patient_id,
            language=language,
            start_time=time.strftime("%Y-%m-%d %H:%M:%S")
        )

        # Load models with language-specific ASR
        self.load_models(language)

        print(f"\nüöÄ Starting therapy session for patient: {patient_id}")
        print("="*60)

        # Initial severity assessment to determine starting difficulty
        print("\nüè• Performing initial severity assessment...")
        print("üéôÔ∏è Please say a simple sentence for assessment (e.g., 'Hello' or 'My name is...')")

        initial_audio_path = self.record_speech(duration=3)  # Shorter for initial assessment
        if initial_audio_path:
            # Try to get a basic transcription or use a default
            initial_transcription = self.transcribe_audio(initial_audio_path, language)
            if not initial_transcription:
                initial_transcription = "hello"  # Fallback

            # Analyze basic pronunciation
            basic_analysis = self.analyze_pronunciation("hello", initial_transcription)

            # Assess initial severity
            initial_severity = self.assess_severity(initial_audio_path, basic_analysis)
            print(f"üè• Initial Assessment: {initial_severity['severity_name']} (WAB-AQ: {initial_severity['wab_aq_score']:.1f})")

            # Determine starting difficulty based on severity
            self.session.current_difficulty = self.determine_starting_difficulty(initial_severity)

            # Clean up initial audio
            try:
                os.unlink(initial_audio_path)
            except:
                pass
        else:
            print("‚ö†Ô∏è Initial assessment failed, starting with easy difficulty")
            self.session.current_difficulty = 'easy'

        try:
            while True:
                # Get sentences for current difficulty
                available_sentences = self.sentences_db[language][self.session.current_difficulty]

                if not available_sentences:
                    print(f"‚ùå No sentences available for {self.session.current_difficulty} difficulty")
                    break

                # Select random sentence from current difficulty
                sentence = random.choice(available_sentences)

                print(f"\nüìù Practice sentence: {sentence.text}")
                print(f"üéØ Difficulty: {sentence.difficulty} | Category: {sentence.category}")
                print(f"üîë Target words: {', '.join(sentence.target_words)}")

                # Play TTS example (optional)
                play_example = input("\nüîä Play pronunciation example? (y/n): ").lower().strip()
                if play_example == 'y':
                    print("üîä Playing pronunciation example...")
                    self.tts.speak(sentence.text, language=language)

                # Record speech
                audio_path = self.record_speech()
                if not audio_path:
                    print("‚ùå Recording failed, skipping this round...")
                    continue

                # Transcribe
                transcription = self.transcribe_audio(audio_path, language)

                if not transcription:
                    print("‚ùå Transcription failed, skipping this round...")
                    continue

                print(f"üó£Ô∏è  You said: {transcription}")

                # Analyze pronunciation with detailed feedback
                analysis = self.analyze_pronunciation(sentence.text, transcription)

                print(f"üìä Feedback: {analysis['feedback']}")
                print(f"üîπ Accuracy: {analysis['accuracy']}")

                # Show detailed error analysis if available
                if analysis.get('detailed_errors'):
                    print(f"üîç Error Details:")
                    for error in analysis['detailed_errors'][:3]:  # Show top 3 errors
                        print(f"   ‚Ä¢ {error}")

                # Generate and show corrective feedback
                corrective_feedback = self.generate_corrective_feedback(analysis, sentence.text)
                if corrective_feedback.get('practice_suggestions'):
                    print(f"üí° Practice Tips:")
                    for suggestion in corrective_feedback['practice_suggestions'][:2]:  # Show top 2 suggestions
                        print(f"   ‚Ä¢ {suggestion}")

                # Generate comprehensive audio feedback
                self._generate_audio_feedback(sentence.text, analysis, corrective_feedback, language)

                # Assess severity (pass pronunciation analysis for better estimation)
                severity_info = self.assess_severity(audio_path, analysis)
                print(f"üè• Severity: {severity_info['severity_name']} (WAB-AQ: {severity_info['wab_aq_score']:.1f})")

                # Update session stats
                self.session.total_attempts += 1
                if analysis['accuracy'] in ['excellent', 'good']:
                    self.session.correct_attempts += 1

                # Store session data
                session_data = {
                    'sentence': sentence.text,
                    'target': sentence.text,
                    'spoken': transcription,
                    'accuracy': analysis['accuracy'],
                    'similarity': analysis['similarity'],
                    'severity': severity_info['severity_name'],
                    'wab_aq_score': severity_info['wab_aq_score'],
                    'detailed_errors': analysis.get('detailed_errors', []),
                    'practice_suggestions': corrective_feedback.get('practice_suggestions', []),
                    'timestamp': time.strftime("%H:%M:%S")
                }
                self.session.session_sentences.append(session_data)

                # Difficulty adjustment (consider both accuracy and severity)
                accuracy_rate = self.session.correct_attempts / max(self.session.total_attempts, 1)

                # Get recent severity trend
                recent_severities = [s.get('wab_aq_score', 50) for s in self.session.session_sentences[-5:]]
                avg_recent_severity = sum(recent_severities) / len(recent_severities) if recent_severities else 50

                # Adjust difficulty based on performance and severity
                if accuracy_rate >= 0.8 and avg_recent_severity >= 60:
                    # High accuracy AND good recent performance - can progress
                    if self.session.current_difficulty == 'easy':
                        self.session.current_difficulty = 'medium'
                        print("üìà Progressing to medium difficulty!")
                    elif self.session.current_difficulty == 'medium' and accuracy_rate >= 0.9:
                        self.session.current_difficulty = 'hard'
                        print("üìà Progressing to hard difficulty!")
                elif accuracy_rate >= 0.7 and self.session.current_difficulty == 'easy' and avg_recent_severity >= 50:
                    # Good performance - move to medium
                    self.session.current_difficulty = 'medium'
                    print("üìà Progressing to medium difficulty!")
                elif accuracy_rate < 0.4 or avg_recent_severity < 40:
                    # Struggling - adjust down for more practice
                    if self.session.current_difficulty == 'hard':
                        self.session.current_difficulty = 'medium'
                        print("üìâ Adjusting to medium difficulty for more practice")
                    elif self.session.current_difficulty == 'medium' and accuracy_rate < 0.3:
                        self.session.current_difficulty = 'easy'
                        print("üìâ Adjusting to easy difficulty for more practice")
                elif avg_recent_severity < 30 and self.session.current_difficulty != 'easy':
                    # Very severe recent assessments - prioritize easy sentences
                    self.session.current_difficulty = 'easy'
                    print("üéØ Focusing on easy sentences to build confidence")

                # Continue or exit
                cont = input("\nüîÑ Continue to next sentence? (y/n): ").lower().strip()
                if cont != 'y':
                    break

                # Clean up audio file
                try:
                    os.unlink(audio_path)
                except:
                    pass

        except KeyboardInterrupt:
            print("\n\n‚èπÔ∏è  Therapy session interrupted by user")
        except Exception as e:
            print(f"\n‚ùå Therapy session error: {e}")
        finally:
            # Save session data
            self._save_session_data()

    def _save_session_data(self):
        """Save session data to JSON file."""
        try:
            os.makedirs("therapy_sessions", exist_ok=True)
            filename = f"therapy_sessions/{self.session.patient_id}_{self.session.language}.json"

            session_dict = asdict(self.session)
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(session_dict, f, ensure_ascii=False, indent=2)

            print(f"\nüíæ Session data saved to: {filename}")
            print(f"üìà Final Stats - Attempts: {self.session.total_attempts}, "
                  f"Correct: {self.session.correct_attempts}, "
                  f"Accuracy: {self.session.correct_attempts/max(self.session.total_attempts, 1)*100:.1f}%")

        except Exception as e:
            print(f"‚ùå Failed to save session data: {e}")


def main():
    """Main function to run the interactive speech therapy system."""
    try:
        therapy_system = InteractiveSpeechTherapy()
        therapy_system.run_therapy_session()
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Program interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Program error: {e}")


if __name__ == "__main__":
    main()


